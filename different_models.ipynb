{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE SKLEARN DIFFERENT MODLELS AND FIND ONE/ONES WITH BEST PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math \n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_inputs = pd.read_csv(\"train.csv\")\n",
    "train_inputs = np.array(train_inputs)[:,:-1] \n",
    "\n",
    "train_labels = pd.read_csv(\"train_result.csv\")\n",
    "train_labels = np.array(train_labels)[:,1] \n",
    "\n",
    "test_inputs = pd.read_csv(\"test.csv\")\n",
    "test_inputs = np.array(test_inputs)[:,:-1] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Each Image is 1568 feature-long. \n",
    "-Each image contains 2 digits.\n",
    "    - Representing a 56x28 pixel image \n",
    "\n",
    "-Each digit is a total of 784 pixel (i.e. 1568/2)\n",
    "    - Representing a 28x28 pixel image \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try displaying one image \n",
    "sampleImage = train_inputs[1,:]\n",
    "print(sampleImage.shape)\n",
    "fig = plt.figure\n",
    "image = np.reshape(sampleImage, (28,56))\n",
    "plt.imshow(image, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of label data. \n",
    "Labels go from 0 to 18 and we observe a bell-shaped (gaussian-like) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels summary\n",
    "\n",
    "from collections import Counter\n",
    "print(train_labels.shape)\n",
    "print(np.unique(train_labels))\n",
    "c = Counter(train_labels)\n",
    "plt.bar(c.keys(), c.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stackoverflow suggested solution for one-hot encoding - Source : https://stackoverflow.com/questions/38592324/one-hot-encoding-using-numpy\n",
    "#@staticmethod\n",
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])\n",
    "\n",
    "Y_onehot_train = get_one_hot(np.int_(train_labels), np.unique(train_labels).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consusion matrix for calculating errors\n",
    "\n",
    "def conf_matrix(testlabels, predlabels):\n",
    "\n",
    "    n_classes = 19 \n",
    "    matrix = np.zeros((n_classes,n_classes))\n",
    "    \n",
    "\n",
    "    for (test, pred) in zip(testlabels, predlabels):\n",
    "        matrix[int(test)-1,int(pred)-1]+=1\n",
    "    return matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting train to use data as validation data\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(train_inputs, train_labels, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1 = svm.SVC(kernel=\"rbf\", C=5, gamma = 0.05)\n",
    "svm1.fit(train_inputs, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2 = svm.SVC(kernel = 'poly')\n",
    "svm2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm3 = svm.SVC(kernel=\"sigmoid\")\n",
    "svm3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_pred_svm1 = svm1.predict(X_test)\n",
    "classes_pred_svm2 = svm2.predict(X_test)\n",
    "classes_pred_svm3 = svm3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateError(classes_pred):\n",
    "    \n",
    "    confmat = conf_matrix(y_test, classes_pred)\n",
    "    sum_preds = np.sum(confmat)\n",
    "    sum_correct = np.sum(np.diag(confmat))\n",
    "    print(\"The test error is \", round(100 * (1.0 - (float(sum_correct) / float(sum_preds))), 2), \"%\")\n",
    "\n",
    "\n",
    "calculateError(classes_pred_svm1)\n",
    "calculateError(classes_pred_svm2)\n",
    "calculateError(classes_pred_svm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order : \n",
    "\n",
    "svm1 = svm.SVC(kernel=\"rbf\", C=5, gamma = 0.05)\n",
    "svm2 = svm.SVC(kernel=\"poly\")\n",
    "svm3 = svm.SVC(kernel=\"sigmoid\")\n",
    "\n",
    "\n",
    "\n",
    "The test error is  55.43 %\n",
    "The test error is  26.04 %\n",
    "The test error is  93.5 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Standardisation\n",
    "svm1_std = make_pipeline(StandardScaler(), svm.SVC(kernel=\"rbf\", C=5, gamma = 0.05))\n",
    "svm1_std.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2_std = make_pipeline(StandardScaler(), svm.SVC(kernel=\"poly\"))\n",
    "svm2_std.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm3_std = make_pipeline(StandardScaler(), svm.SVC(kernel=\"sigmoid\"))\n",
    "# svm3_std.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_pred_svm1_std = svm1_std.predict(X_test)\n",
    "classes_pred_svm2_std = svm2_std.predict(X_test)\n",
    "# classes_pred_svm3_std = svm3_std.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la standardisation n'a pas eu un effet positif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For Standardized data - SVM with kernel rbf\") ; calculateError(classes_pred_svm1_std)\n",
    "print(\"For Standardized data - SVM with kernel poly\") ;calculateError(classes_pred_svm2_std)\n",
    "# print(\"For SVM with kernel sigmoid \\n\") ;calculateError(classes_pred_svm3_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAIVES BAYES \n",
    "\n",
    "Sans aucune forme de pré-traitement, le classifieur Naive Bayes obtient un score de 7,39% seulement sur D_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianClassifier = GaussianNB()\n",
    "gaussianClassifier.fit(X_train, y_train)\n",
    "pred_test = gaussianClassifier.predict(X_test)\n",
    "print(accuracy_score(y_test, pred_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réduire le nombre de features que doit apprendre le Naive Bayes, on va faire une PCA en premier. \n",
    "\n",
    "On va essayer de trouver le parametre optimal d'une PCA, suivi d'un classifieur Bayes naif.\n",
    "Pour PCA, il s'agit de savoir combien de composantes principales garder, pour generer la meilleure prediction par Naive Bayes.\n",
    "\n",
    "On peut regrouper la procédure (PCA ensuite Bayes) dans un pipeline sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to training data and predict on test data (PCA + Naive Bayes)\n",
    "PCA_NaiveBayes = make_pipeline(PCA(n_components=25), GaussianNB())\n",
    "PCA_NaiveBayes.fit(X_train, y_train)\n",
    "pred_test = PCA_NaiveBayes.predict(X_test)\n",
    "print(accuracy_score(y_test, pred_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_components_to_test = 250\n",
    "kComponents = [k+1 for k in range(max_components_to_test)]\n",
    "def findBestNumberComponentsForPCA_NaiveBayes() : \n",
    "    accuracyArr = []\n",
    "\n",
    "    bestParameter = -1\n",
    "    bestAccuracy = -1\n",
    "    for k in kComponents : \n",
    "        # Fit to training data and predict on test data (PCA with k components + Naive Bayes)\n",
    "        PCA_NaiveBayes = make_pipeline(PCA(n_components=k), GaussianNB())\n",
    "        PCA_NaiveBayes.fit(X_train, y_train)\n",
    "        pred_test = PCA_NaiveBayes.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred_test)*100\n",
    "        if k%10 ==0 : print(f'Accuracy for PCA with {k} components is : {accuracy}%')\n",
    "        accuracyArr.append(accuracy)\n",
    "        if accuracy>bestAccuracy :\n",
    "            bestAccuracy = accuracy\n",
    "            bestParameter = k\n",
    "\n",
    "    return bestParameter, bestAccuracy, accuracyArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestParameter, bestAccuracy, accuracyArr = findBestNumberComponentsForPCA_NaiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que la précision du classifieur Naive Bayes va en augmentant jusqu'à un certain seuil, au delà duquel la précision du classifieur diminue graduellement. \n",
    "\n",
    "Le nombre optimal de Composantes Principales à utiliser ici avec Naive Bayes est 64, et cela permet un score de 23.56%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Principal Components that generated the best prediction with Naive Bayes : {bestParameter}')\n",
    "print(f'Accuracy : {bestAccuracy}')\n",
    "\n",
    "plt.plot(kComponents, accuracyArr)\n",
    "plt.title('Accuracy % on randomized test data when using Naives Bayes with the K Principal components of training data')\n",
    "plt.xlabel('Number of components used (post-PCA)')\n",
    "plt.ylabel('Score on test data (% accuracy)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_mat(x, Y, p=2):\n",
    "    return (np.sum((np.abs(x - Y)) ** p, axis=1)) ** (1.0 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspired by labo2\n",
    "class NeighborhoodClassifier:\n",
    "    def __init__(self, dist_func=minkowski_mat, k=1):\n",
    "\n",
    "        self.dist_func = dist_func\n",
    "        self.k = k\n",
    "\n",
    "    # The train function for knn \n",
    "    def train(self, train_inputs, train_labels):\n",
    "        self.train_inputs = train_inputs\n",
    "        self.train_labels = train_labels\n",
    "        self.n_classes = len(np.unique(train_labels))\n",
    "\n",
    "    # The prediction function takes as input test_data and returns an array containing the predicted classes. \n",
    "    def compute_predictions(self, test_data):\n",
    "        # Initialization of the count matrix and the predicted classes array\n",
    "        num_test = test_data.shape[0] #nombre de lignes de test\n",
    "        counts = np.ones((num_test, self.n_classes)) \n",
    "        classes_pred = np.zeros(num_test) \n",
    "        # For each test datapoint\n",
    "        \n",
    "        for (i, ex) in enumerate(test_data):\n",
    "  \n",
    "          \n",
    "            # i is the row index\n",
    "            # ex is the i'th row\n",
    "\n",
    "            # Find the distances to each training set point using dist_func\n",
    "            \n",
    "          distances = self.dist_func(ex,self.train_inputs)\n",
    "\n",
    "\n",
    "          labelToCount = np.array([])\n",
    "          \n",
    "          labeltoCount = [self.train_labels[int(x)] for x in np.argsort(distances)[:self.k]]\n",
    "\n",
    "            \n",
    "            # Calculate the number of neighbors belonging to each class and write them in counts[i,:]\n",
    "            \n",
    "          for label in range(self.n_classes):\n",
    "            counts[i,label] = labeltoCount.count(label+1)\n",
    "\n",
    "           \n",
    "            # From the counts matrix, define classes_pred[i]\n",
    "            \n",
    "\n",
    "          classes_pred[i] = int(np.argmax(counts[i]) + 1) \n",
    "        return classes_pred.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist\n",
    "\n",
    "\n",
    "# Number of classes\n",
    "n_classes = 19\n",
    "# Size of training set\n",
    "n_train = 40000\n",
    "\n",
    "data = np.array(train_inputs)[:50000,:] #n_train and the data range can be changed \n",
    "labels = np.array(train_labels)[:50000] \n",
    "\n",
    "\n",
    "# The columns (features) on which to train our model\n",
    "\n",
    "train_cols = [x for x in range(56*28)]\n",
    "\n",
    "\n",
    "# Comment to have random (non-deterministic) results\n",
    "random.seed(3395)\n",
    "# Randomly choose indexes for the train and test dataset\n",
    "inds = list(range(data.shape[0]))\n",
    "random.shuffle(inds)\n",
    "train_inds = inds[:n_train]\n",
    "test_inds = inds[n_train:]\n",
    "\n",
    "# Split the data into both sets\n",
    "train_set = data[train_inds, :]\n",
    "train_set = train_set[:, train_cols] \n",
    "valid_set = data[test_inds, :]\n",
    "valid_set = valid_set[:, train_cols]\n",
    "\n",
    "# Separate the test set into inputs and labels\n",
    "valid_inputsKNN = valid_set\n",
    "valid_labelsKNN = labels[test_inds]\n",
    "train_inputsKNN = train_set\n",
    "train_labelsKNN = labels[train_inds]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist\n",
    "\n",
    "\n",
    "# Number of classes\n",
    "n_classes = 19\n",
    "# Size of training set\n",
    "n_train=50000\n",
    "\n",
    " \n",
    "# The columns (features) on which to train our model\n",
    "# For gridplot to work, len(train_cols) should be 2\n",
    "train_cols = [x for x in range(56*28)]\n",
    "\n",
    "\n",
    "# Comment to have random (non-deterministic) results\n",
    "random.seed(3395)\n",
    "# Randomly choose indexes for the train and test dataset\n",
    "inds = list(range(data.shape[0]))\n",
    "random.shuffle(inds)\n",
    "train_inds = inds[:n_train]\n",
    "\n",
    "\n",
    "# Split the data into both sets\n",
    "train_set = train_inputs[train_inds, :]\n",
    "test_set = test_inputs\n",
    "\n",
    "\n",
    "# Separate the test set into inputs and labels\n",
    "test_inputsKNN = test_set\n",
    "train_inputsKNN = train_set\n",
    "train_labelsKNN = train_labels[train_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of neighbors (k) for knn\n",
    "k = 9\n",
    "\n",
    "# Create the classifiers\n",
    "knn = NeighborhoodClassifier(dist_func=minkowski_mat, k=k)\n",
    "\n",
    "\n",
    "# We train the models\n",
    "knn.train(train_inputsKNN, train_labelsKNN)\n",
    "\n",
    "\n",
    "# We get predictions\n",
    "classes_pred_knn = knn.compute_predictions(test_inputsKNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(model, classes_pred):\n",
    "    # Confusion Matrix\n",
    "    confmat = conf_matrix(valid_labelsKNN, classes_pred)\n",
    "    print('The confusion matrix is:')\n",
    "\n",
    "    # Test error\n",
    "    sum_preds = np.sum(confmat)\n",
    "    sum_correct = np.sum(np.diag(confmat))\n",
    "    print(\"The test error is \", round(100 * (1.0 - (float(sum_correct) / float(sum_preds))), 2), \"%\")\n",
    "\n",
    "show_results(knn, classes_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation des parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_error(k):\n",
    "   \n",
    "    knn = NeighborhoodClassifier(dist_func=minkowski_mat, k=k)\n",
    "    knn.train(train_inputs, train_labels)\n",
    "    classes_pred_knn = knn.compute_predictions(test_inputs)\n",
    "    confmat = conf_matrix(test_labels, classes_pred_knn)\n",
    "    print(k)\n",
    "    return 1.0 - (float(np.sum(np.diag(confmat))) / float(np.sum(confmat)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 30), [get_test_error(k) for k in range(1, 30)], label='test error')\n",
    "plt.legend()\n",
    "plt.xlabel('number of neighbors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.linkedin.com/pulse/choosing-number-hidden-layers-neurons-neural-networks-sachdev/\n",
    "\n",
    "https://victorzhou.com/blog/keras-cnn-tutorial/\n",
    "\n",
    "https://keras.io/examples/vision/mnist_convnet/ # 99% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist     \n",
    "from keras.models import Sequential  \n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Activation \n",
    "from keras.utils import np_utils                         \n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sur Valid set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_inputs, train_labels, test_size=0.30)\n",
    "\n",
    "#Sur test set\n",
    "\"\"\"\n",
    "X_train = train_inputs\n",
    "y_train = train_labels\n",
    "X_test = test_inputs\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert y to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = 19\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, no_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, no_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(800, input_shape=(1568,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(172))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(170))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(19))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "          batch_size=128, epochs=20,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print(model.predict(X_test))\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Class\")\n",
    "submission = pd.concat([pd.Series(np.arange(0,len(X_test) ).astype(int),name = \"Index\"),results],axis = 1)\n",
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c5cc85293f5813557ec94562dc537c0fc56637b5ec37532782b006ba2c53b605"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
